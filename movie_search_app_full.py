#!/usr/bin/env python3
"""
movie_search_app_full.py

A Streamlit web application for semantic movie search using a precomputed
FAISS index and embeddings. It optionally uses Cohere's Rerank API to
improve the relevance of final search results.

Required files (must be generated by `build_faiss_index.py` first):
 - movie_meta.parquet
 - movie_embeddings.npy
 - faiss.index

To enable Cohere reranking, set the COHERE_API_KEY environment variable.
"""
import os
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import faiss
import numpy as np
import pandas as pd
import streamlit as st
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer

# Attempt to import cohere, but don't fail if it's not installed,
# as it's an optional dependency for the reranking feature.
try:
    import cohere
    COHERE_AVAILABLE = True
except ImportError:
    COHERE_AVAILABLE = False

# --- 1. Configuration ---
st.set_page_config(layout="wide", page_title="Movie Search Engine")

# --- File Paths ---
EMBEDDINGS_PATH = "movie_embeddings.npy"
META_PATH = "movie_meta.parquet"
FAISS_INDEX_PATH = "faiss.index"

# --- Model Configuration ---
# This must match the model used in `build_faiss_index.py`
EMBEDDING_MODEL_NAME = "Qwen/Qwen3-Embedding-0.6B"
COHERE_RERANK_MODEL = "rerank-english-v3.0"

# --- 2. Services & Data Loading (with Caching) ---

@st.cache_resource
def load_sentence_transformer() -> SentenceTransformer:
    """Loads and caches the SentenceTransformer model."""
    return SentenceTransformer(EMBEDDING_MODEL_NAME)

@st.cache_resource
def load_search_data() -> Tuple[pd.DataFrame, np.ndarray, faiss.Index]:
    """
    Loads and caches the movie metadata, embeddings, and FAISS index.
    Raises FileNotFoundError if any of the required files are missing.
    """
    for p in (META_PATH, EMBEDDINGS_PATH, FAISS_INDEX_PATH):
        if not Path(p).exists():
            st.error(f"FATAL: Required data file not found: {p}. Please run `build_faiss_index.py` first.")
            st.stop()
            
    df = pd.read_parquet(META_PATH)
    embeddings = np.load(EMBEDDINGS_PATH)
    index = faiss.read_index(FAISS_INDEX_PATH)
    return df, embeddings, index

@st.cache_resource
def get_cohere_client() -> Optional['cohere.Client']:
    """
    Initializes and caches the Cohere client if the API key is available.
    Returns None if the key is not found or the cohere package is not installed.
    """
    load_dotenv()  # Load from .env file if present
    api_key = os.environ.get("COHERE_API_KEY")
    if not api_key:
        st.sidebar.warning("COHERE_API_KEY not found. Reranking is disabled.", icon="⚠️")
        return None
    if not COHERE_AVAILABLE:
        st.sidebar.error("`cohere` package not installed. Please run `pip install cohere` to enable reranking.")
        return None
    return cohere.Client(api_key)

# --- 3. Core Logic ---

def encode_query(query_text: str, model: SentenceTransformer) -> np.ndarray:
    """Encodes the user's query text into a normalized embedding vector."""
    query_embedding = model.encode([query_text], normalize_embeddings=True)
    return np.asarray(query_embedding, dtype="float32")

def search_faiss(index: faiss.Index, query_embedding: np.ndarray, top_k: int) -> List[Dict]:
    """
    Performs a search on the FAISS index to get the top_k most similar movie candidates.

    Returns:
        A list of dictionaries, each containing the 'pos' (position/index) and 'score'
        (cosine similarity) of a candidate.
    """
    distances, indices = index.search(query_embedding, top_k)
    
    # Flatten the results and filter out invalid indices (-1)
    results = [
        {"pos": int(idx), "score": float(dist)}
        for dist, idx in zip(distances[0], indices[0])
        if idx != -1
    ]
    return results

def rerank_with_cohere(client: 'cohere.Client', query: str, candidates: pd.DataFrame) -> List[Dict]:
    """
    Uses the Cohere Rerank API to reorder the candidate documents based on relevance to the query.

    Args:
        client: The Cohere client instance.
        query: The user's search query.
        candidates: A DataFrame of candidate movies from the initial FAISS search.

    Returns:
        A list of dictionaries sorted by the new rerank score.
    """
    docs = (candidates["title"] + " - " + candidates["overview"]).tolist()
    
    try:
        reranked_results = client.rerank(
            model=COHERE_RERANK_MODEL,
            query=query,
            documents=docs,
            top_n=len(docs)
        )
    except cohere.core.ApiError as e:
        st.error(f"Cohere API Error: {e}. Falling back to semantic search results.")
        return []

    # Map reranked results back to original positions and add the new score
    reranked_indices = [res.index for res in reranked_results.results]
    
    # Create a new DataFrame from the reranked order
    reranked_df = candidates.iloc[reranked_indices].copy()
    reranked_df["rerank_score"] = [res.relevance_score for res in reranked_results.results]
    
    return reranked_df.to_dict('records')


@st.cache_data
def apply_filters(df: pd.DataFrame, min_year: int, max_year: int) -> pd.DataFrame:
    """

    Applies filters to the DataFrame. Cached for performance.
    
    Args:
        df: The DataFrame of movies to filter.
        min_year: The minimum release year.
        max_year: The maximum release year.
        
    Returns:
        A filtered pandas DataFrame.
    """
    filtered_df = df.copy()
    if min_year > 1800:
        filtered_df = filtered_df[filtered_df["year"] >= min_year]
    if max_year < 2050:
        filtered_df = filtered_df[filtered_df["year"] <= max_year]
    return filtered_df

# --- 4. UI Components ---

def render_sidebar(df: pd.DataFrame):
    """Renders the sidebar with search controls and filters."""
    st.sidebar.header("🔍 Search Controls")
    top_k = st.sidebar.slider(
        "Candidates to retrieve (Top-K)", 
        min_value=50, max_value=500, value=200, step=50,
        help="Number of initial candidates to pull from the vector search. Higher values may find more niche results but increase reranking cost."
    )
    display_k = st.sidebar.slider(
        "Results to display", 
        min_value=5, max_value=50, value=10, step=5
    )

    st.sidebar.header("⚙️ Reranking")
    use_cohere = st.sidebar.checkbox(
        "Use Cohere Rerank", value=True,
        help="Enhance search results with Cohere's reranking model. Requires a COHERE_API_KEY."
    )

    st.sidebar.header("🎬 Filters")
    min_year, max_year = st.sidebar.select_slider(
        "Filter by Release Year",
        options=range(int(df['year'].min()), int(df['year'].max()) + 1),
        value=(1980, 2024)
    )
    
    return top_k, display_k, use_cohere, min_year, max_year

def render_results(results: List[Dict], use_reranker: bool):
    """Renders the search results in a clean format."""
    if not results:
        st.warning("No results found matching your criteria.")
        return

    score_key = "rerank_score" if use_reranker else "score"
    score_label = "Relevance" if use_reranker else "Similarity"

    for i, row in enumerate(results):
        with st.container(border=True):
            st.subheader(f"{i + 1}. {row['title']} ({row['year']})")
            st.caption(f"**{score_label}:** `{row[score_key]:.4f}` | **Genres:** `{row['genres']}`")
            st.write(row["overview"])

# --- 5. Main Application ---

def main():
    """Main function to run the Streamlit app."""
    st.title("🎬 Semantic Movie Search")
    st.markdown("Search for movies based on plot, themes, or concepts. Optionally use **Cohere Rerank** for enhanced relevance.")

    # --- Load resources ---
    model = load_sentence_transformer()
    df, embeddings, index = load_search_data()
    cohere_client = get_cohere_client()

    # --- Render UI ---
    top_k, display_k, use_cohere, min_year, max_year = render_sidebar(df)
    
    query_text = st.text_input("Search for a movie (e.g., 'a robot falls in love with a human')", "")

    if st.button("Search", type="primary") and query_text.strip():
        start_time = time.time()
        
        # --- Step 1: Encode query and perform FAISS search ---
        with st.spinner("Searching for initial candidates..."):
            query_embedding = encode_query(query_text, model)
            candidates_raw = search_faiss(index, query_embedding, top_k)
            candidate_positions = [c["pos"] for c in candidates_raw]
            candidate_scores = {c["pos"]: c["score"] for c in candidates_raw}

        # --- Step 2: Retrieve metadata and apply filters ---
        candidates_df = df[df["__pos"].isin(candidate_positions)].copy()
        candidates_df["score"] = candidates_df["__pos"].map(candidate_scores)
        
        filtered_candidates = apply_filters(candidates_df, min_year, max_year)
        
        if filtered_candidates.empty:
            st.warning("No candidates found after applying filters.")
            return

        # --- Step 3: (Optional) Rerank with Cohere ---
        final_results = []
        use_reranker_for_results = use_cohere and cohere_client is not None
        
        if use_reranker_for_results:
            with st.spinner("Reranking results with Cohere for better relevance..."):
                reranked_list = rerank_with_cohere(cohere_client, query_text, filtered_candidates)
                if reranked_list:
                    final_results = reranked_list
                else: # Fallback if reranking fails
                    final_results = filtered_candidates.sort_values("score", ascending=False).to_dict('records')
                    use_reranker_for_results = False # Update flag to show correct score
        else:
            final_results = filtered_candidates.sort_values("score", ascending=False).to_dict('records')

        end_time = time.time()
        st.success(f"Found {len(final_results)} results in {end_time - start_time:.2f} seconds.")
        
        # --- Step 4: Display final results ---
        render_results(final_results[:display_k], use_reranker_for_results)

if __name__ == "__main__":
    main()